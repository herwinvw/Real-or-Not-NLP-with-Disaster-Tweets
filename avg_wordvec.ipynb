{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier using average wordvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_train = pd.read_pickle('train_wordvec_glove.twitter.27B.200d.pickle')\n",
    "wordvec_test = pd.read_pickle('test_wordvec_glove.twitter.27B.200d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>glove_cleaned_text</th>\n",
       "      <th>wordvec</th>\n",
       "      <th>keyword_wordvec</th>\n",
       "      <th>wordvec_concat</th>\n",
       "      <th>wordvec_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>our deeds are the reason of this &lt;hashtag&gt; ear...</td>\n",
       "      <td>[0.17742333, 0.0825951, 0.13578425, 0.11371653...</td>\n",
       "      <td>[0.17742333, 0.0825951, 0.13578425, 0.11371653...</td>\n",
       "      <td>[[-0.05753900110721588, -0.018967999145388603,...</td>\n",
       "      <td>[0.41576690107051817, 1.0901237577199936, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>[-0.14923862, 0.020581482, -0.027608752, -0.11...</td>\n",
       "      <td>[-0.14923862, 0.020581482, -0.027608752, -0.11...</td>\n",
       "      <td>[[-0.4864000082015991, 0.07588999718427658, 0....</td>\n",
       "      <td>[-1.1782405631882804, 0.4126361182757786, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[-0.03266476, 0.051652886, -0.13747665, 0.0763...</td>\n",
       "      <td>[-0.03266476, 0.051652886, -0.13747665, 0.0763...</td>\n",
       "      <td>[[0.26405999064445496, 0.1720300018787384, 0.0...</td>\n",
       "      <td>[-0.1711904447187077, 0.5443525652993809, -1.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>&lt;number&gt; people receive &lt;hashtag&gt; wildfires ev...</td>\n",
       "      <td>[0.15625294, 0.017215075, -0.020121612, -0.078...</td>\n",
       "      <td>[0.15625294, 0.017215075, -0.020121612, -0.078...</td>\n",
       "      <td>[[0.41253000497817993, -0.3959699869155884, 0....</td>\n",
       "      <td>[0.48644813439912266, 1.4941825361715422, -1.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>just got sent this photo from ruby &lt;hashtag&gt; a...</td>\n",
       "      <td>[0.13052966, 0.008564685, -0.009015768, -0.093...</td>\n",
       "      <td>[0.13052966, 0.008564685, -0.009015768, -0.093...</td>\n",
       "      <td>[[-0.19265000522136688, 0.4586299955844879, -0...</td>\n",
       "      <td>[0.5162669516661588, 0.5474840612972484, -0.59...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                       cleaned_text  \\\n",
       "0       1  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1       1             Forest fire near La Ronge Sask. Canada   \n",
       "2       1  All residents asked to 'shelter in place' are ...   \n",
       "3       1  people receive wildfires evacuation orders in ...   \n",
       "4       1  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                  glove_cleaned_text  \\\n",
       "0  our deeds are the reason of this <hashtag> ear...   \n",
       "1             forest fire near la ronge sask. canada   \n",
       "2  all residents asked to 'shelter in place' are ...   \n",
       "3  <number> people receive <hashtag> wildfires ev...   \n",
       "4  just got sent this photo from ruby <hashtag> a...   \n",
       "\n",
       "                                             wordvec  \\\n",
       "0  [0.17742333, 0.0825951, 0.13578425, 0.11371653...   \n",
       "1  [-0.14923862, 0.020581482, -0.027608752, -0.11...   \n",
       "2  [-0.03266476, 0.051652886, -0.13747665, 0.0763...   \n",
       "3  [0.15625294, 0.017215075, -0.020121612, -0.078...   \n",
       "4  [0.13052966, 0.008564685, -0.009015768, -0.093...   \n",
       "\n",
       "                                     keyword_wordvec  \\\n",
       "0  [0.17742333, 0.0825951, 0.13578425, 0.11371653...   \n",
       "1  [-0.14923862, 0.020581482, -0.027608752, -0.11...   \n",
       "2  [-0.03266476, 0.051652886, -0.13747665, 0.0763...   \n",
       "3  [0.15625294, 0.017215075, -0.020121612, -0.078...   \n",
       "4  [0.13052966, 0.008564685, -0.009015768, -0.093...   \n",
       "\n",
       "                                      wordvec_concat  \\\n",
       "0  [[-0.05753900110721588, -0.018967999145388603,...   \n",
       "1  [[-0.4864000082015991, 0.07588999718427658, 0....   \n",
       "2  [[0.26405999064445496, 0.1720300018787384, 0.0...   \n",
       "3  [[0.41253000497817993, -0.3959699869155884, 0....   \n",
       "4  [[-0.19265000522136688, 0.4586299955844879, -0...   \n",
       "\n",
       "                                       wordvec_tfidf  \n",
       "0  [0.41576690107051817, 1.0901237577199936, 0.07...  \n",
       "1  [-1.1782405631882804, 0.4126361182757786, 0.19...  \n",
       "2  [-0.1711904447187077, 0.5443525652993809, -1.2...  \n",
       "3  [0.48644813439912266, 1.4941825361715422, -1.2...  \n",
       "4  [0.5162669516661588, 0.5474840612972484, -0.59...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(wordvec_train, on=['id'])\n",
    "test = test.merge(wordvec_test, on=['id'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def get_X(df, col):\n",
    "    X = []\n",
    "    for index, row in df.iterrows():\n",
    "        x = row[col]\n",
    "        X.append(x)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = get_X(train, 'wordvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(model, X, y, X_test, name):\n",
    "    fit = model.fit(X,y)\n",
    "    pred = model.predict(X_test)\n",
    "    submission = pd.DataFrame({\"id\":test['id'], \"target\":pred})\n",
    "    submission.to_csv(name+'.csv', index=False)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression(max_iter = 1000)\n",
    "params = {'C': [0.05, 0.1, 0.2, 0.5, 0.75, 1, 1.5, 2, 4]}\n",
    "clf = GridSearchCV(lg, params, scoring=\"f1\", verbose=1, n_jobs=-2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([7.78051186, 7.32899547, 7.16335011, 6.84515262, 7.13647914]),\n",
       " 'score_time': array([0.00642347, 0.00513864, 0.00473952, 0.00477815, 0.00473571]),\n",
       " 'test_score': array([0.75061728, 0.72277228, 0.75307629, 0.74166667, 0.75493421]),\n",
       " 'train_score': array([0.7552795 , 0.75857792, 0.7552795 , 0.76297968, 0.74968867])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446133460827962"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42, max_iter=2000)\n",
    "params = {'hidden_layer_sizes': [(1,), (2,), (4,),(8,)], \n",
    "          'learning_rate_init':[0.00005, 0.0001, 0.0002, 0.001]}\n",
    "clf = GridSearchCV(mlp, params, scoring=\"f1\", verbose=1, n_jobs=-2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([145.00500083, 142.96130419, 146.76166844, 158.1616106 ,\n",
       "        133.59070396]),\n",
       " 'score_time': array([0.00425243, 0.01213694, 0.00424147, 0.00535369, 0.00420356]),\n",
       " 'test_score': array([0.75900721, 0.73580247, 0.75562701, 0.73735726, 0.75873274]),\n",
       " 'train_score': array([0.76525631, 0.76303414, 0.76533711, 0.77055756, 0.74923108])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7493053363077024"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  36 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-2)]: Done  80 out of  80 | elapsed:  2.5min finished\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(test, 'wordvec')\n",
    "fit = prepare_submission(clf, X, y, X_test, 'avg_wordvec_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layer_sizes': (4,), 'learning_rate_init': 0.0001}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "params = {'C': [0.05, 0.1, 0.2, 0.5, 0.75, 1, 1.5, 2, 4]}\n",
    "clf = GridSearchCV(svm, params, scoring=\"f1\", verbose=1, n_jobs=-2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([85.51620579, 84.83172464, 85.25083637, 84.61296296, 84.95820141]),\n",
       " 'score_time': array([0.71441388, 0.71049023, 0.78812814, 0.78455281, 0.72308707]),\n",
       " 'test_score': array([0.75653595, 0.7458194 , 0.75294118, 0.74744027, 0.77025898]),\n",
       " 'train_score': array([0.78905926, 0.79093932, 0.76708861, 0.76693937, 0.7849485 ])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7545991551998315"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(test, 'wordvec')\n",
    "fit = prepare_submission(clf, X, y, X_test, 'avg_wordvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.5}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([20.85033793, 20.48873744, 16.8838593 , 16.09859061, 15.4869875 ,\n",
       "        15.13233838, 14.25862041, 14.34904389, 11.32200117]),\n",
       " 'std_fit_time': array([1.72599068, 0.74164895, 2.37157441, 1.36841514, 1.16602543,\n",
       "        1.63879369, 1.51806699, 1.00803528, 2.12964137]),\n",
       " 'mean_score_time': array([4.11234188, 4.0706604 , 3.34466949, 2.89260302, 2.57578387,\n",
       "        2.89069328, 2.34909544, 2.21782842, 1.07016292]),\n",
       " 'std_score_time': array([0.62465848, 0.07952023, 0.65589121, 0.51842836, 0.52976189,\n",
       "        0.14779166, 0.65574025, 0.43018303, 0.35031141]),\n",
       " 'param_C': masked_array(data=[0.05, 0.1, 0.2, 0.5, 0.75, 1, 1.5, 2, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.05},\n",
       "  {'C': 0.1},\n",
       "  {'C': 0.2},\n",
       "  {'C': 0.5},\n",
       "  {'C': 0.75},\n",
       "  {'C': 1},\n",
       "  {'C': 1.5},\n",
       "  {'C': 2},\n",
       "  {'C': 4}],\n",
       " 'split0_test_score': array([0.64403492, 0.67741935, 0.70214753, 0.71389144, 0.72247498,\n",
       "        0.72479564, 0.72166818, 0.71752952, 0.71818182]),\n",
       " 'split1_test_score': array([0.61953488, 0.65770609, 0.69291339, 0.71711092, 0.72020287,\n",
       "        0.72222222, 0.72259136, 0.72636816, 0.72340426]),\n",
       " 'split2_test_score': array([0.66484018, 0.69354839, 0.70742358, 0.72619048, 0.72789116,\n",
       "        0.73141892, 0.74166667, 0.73833333, 0.7319933 ]),\n",
       " 'split3_test_score': array([0.63345865, 0.67572464, 0.69014085, 0.70322019, 0.7033534 ,\n",
       "        0.70547945, 0.70468085, 0.70297872, 0.70667794]),\n",
       " 'split4_test_score': array([0.71195652, 0.72567923, 0.75914894, 0.77968878, 0.78866397,\n",
       "        0.78807413, 0.78628389, 0.78792693, 0.78947368]),\n",
       " 'mean_test_score': array([0.65476503, 0.68601554, 0.71035485, 0.72802036, 0.73251727,\n",
       "        0.73439807, 0.73537819, 0.73462733, 0.7339462 ]),\n",
       " 'std_test_score': array([0.03219514, 0.02285246, 0.02517787, 0.02685764, 0.0292468 ,\n",
       "        0.02816643, 0.02801689, 0.02904054, 0.02894934]),\n",
       " 'rank_test_score': array([9, 8, 7, 6, 5, 3, 1, 2, 4], dtype=int32)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with keywords in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = get_X(train, 'keyword_wordvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   36.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   33.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   34.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   35.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([38.08809638, 35.52230072, 36.57976961, 36.54533672, 36.94821024]),\n",
       " 'score_time': array([0.38468838, 0.37544727, 0.38675475, 0.36254406, 0.38588691]),\n",
       " 'test_score': array([0.75603664, 0.74565037, 0.7589658 , 0.76348548, 0.77222693]),\n",
       " 'train_score': array([0.77671119, 0.78043704, 0.77281309, 0.80423061, 0.77133825])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592730434622285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work less good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train tfidf version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = get_X(train, 'wordvec_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   34.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   35.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:   35.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([37.41883588, 36.20017576, 37.91277766, 37.41486454, 37.63504076]),\n",
       " 'score_time': array([0.37383294, 0.37622619, 0.37766647, 0.37400675, 0.38509059]),\n",
       " 'test_score': array([0.75493421, 0.73710904, 0.75      , 0.75021313, 0.7628692 ]),\n",
       " 'train_score': array([0.79299562, 0.77724325, 0.81613977, 0.79059117, 0.76744186])}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510251164739314"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
