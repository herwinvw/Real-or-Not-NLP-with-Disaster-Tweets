{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional wordvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_train = pd.read_pickle('train_wordvec.pickle')\n",
    "wordvec_test = pd.read_pickle('test_wordvec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>wordvec</th>\n",
       "      <th>keyword_wordvec</th>\n",
       "      <th>wordvec_concat</th>\n",
       "      <th>wordvec_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[[-0.2820900082588196, 0.1519400030374527, -0....</td>\n",
       "      <td>[-2.0410312242232838, 0.1577752003302941, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[[0.3039900064468384, 0.20476000010967255, -0....</td>\n",
       "      <td>[-0.27185601989428204, 0.2042857458194097, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[[0.00997759960591793, -0.20995000004768372, -...</td>\n",
       "      <td>[0.07528745450756767, 0.11175614595413208, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[[-0.19686000049114227, 0.1157900020480156, -0...</td>\n",
       "      <td>[-1.3403782035623277, 1.2000715562275477, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[[-0.02556299977004528, 0.444240003824234, -0....</td>\n",
       "      <td>[-0.7245167245467504, -0.364056259393692, 0.52...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                       cleaned_text  \\\n",
       "0       1  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1       1             Forest fire near La Ronge Sask. Canada   \n",
       "2       1  All residents asked to 'shelter in place' are ...   \n",
       "3       1  people receive wildfires evacuation orders in ...   \n",
       "4       1  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                             wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                     keyword_wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                      wordvec_concat  \\\n",
       "0  [[-0.2820900082588196, 0.1519400030374527, -0....   \n",
       "1  [[0.3039900064468384, 0.20476000010967255, -0....   \n",
       "2  [[0.00997759960591793, -0.20995000004768372, -...   \n",
       "3  [[-0.19686000049114227, 0.1157900020480156, -0...   \n",
       "4  [[-0.02556299977004528, 0.444240003824234, -0....   \n",
       "\n",
       "                                       wordvec_tfidf  \n",
       "0  [-2.0410312242232838, 0.1577752003302941, -0.8...  \n",
       "1  [-0.27185601989428204, 0.2042857458194097, -1....  \n",
       "2  [0.07528745450756767, 0.11175614595413208, -0....  \n",
       "3  [-1.3403782035623277, 1.2000715562275477, 0.11...  \n",
       "4  [-0.7245167245467504, -0.364056259393692, 0.52...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(wordvec_train, on=['id'])\n",
    "test = test.merge(wordvec_test, on=['id'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = max(train['wordvec_concat'].apply(lambda x: x.shape[0]).max(),\n",
    "                test['wordvec_concat'].apply(lambda x: x.shape[0]).max())\n",
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def get_X(df, col):\n",
    "    X = concat = numpy.empty((0, max_words, 300))\n",
    "    for index, row in df.iterrows():\n",
    "        x = numpy.pad(row[col],((0,max_words - row[col].shape[0]),(0, 0)))\n",
    "        X = numpy.append(X, [x], axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = get_X(train, 'wordvec_concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7561, 33, 300)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_model():\n",
    "    conv_model = tf.keras.Sequential([\\\n",
    "        tf.keras.layers.Dropout(0.4, input_shape=(max_words,300)),          \n",
    "        tf.keras.layers.Conv1D(filters=6, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Dropout(0.3),  \n",
    "        tf.keras.layers.Conv1D(filters=8, kernel_size=5, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.2),                           \n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "    ])\n",
    "    return conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_174 (Dropout)        (None, 33, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 31, 6)             5406      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 15, 6)             0         \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 15, 6)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 11, 8)             248       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 5, 8)              0         \n",
      "_________________________________________________________________\n",
      "flatten_66 (Flatten)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 5,695\n",
      "Trainable params: 5,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = get_model()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, train, validation):   \n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation = validation    \n",
    "        self.train = train        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):        \n",
    "        self.val_f1s = []\n",
    "        self.train_f1s = []\n",
    "             \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_targ = self.validation[1]   \n",
    "        val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n",
    "        \n",
    "        train_targ = self.train[1]   \n",
    "        train_predict = (np.asarray(self.model.predict(self.train[0]))).round()   \n",
    "        \n",
    "        val_f1 = f1_score(val_targ, val_predict)\n",
    "        train_f1 = f1_score(train_targ, train_predict)\n",
    "        self.val_f1s.append(round(val_f1, 6))\n",
    "        self.train_f1s.append(round(train_f1, 6))\n",
    "        \n",
    "        print(f'— train_f1: {train_f1} — val_f1: {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting fold 1 ----\n",
      "Epoch 1/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.6742\n",
      "— train_f1: 0.7232365145228216 — val_f1: 0.7063621533442088\n",
      "Epoch 2/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.5399\n",
      "— train_f1: 0.7550328881801873 — val_f1: 0.745736434108527\n",
      "Epoch 3/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4925\n",
      "— train_f1: 0.7679671457905545 — val_f1: 0.7536231884057971\n",
      "Epoch 4/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4811\n",
      "— train_f1: 0.7782274382840955 — val_f1: 0.7653543307086614\n",
      "Epoch 5/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4669\n",
      "— train_f1: 0.7882591093117409 — val_f1: 0.7657232704402516\n",
      "Epoch 6/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4625\n",
      "— train_f1: 0.7910478128179044 — val_f1: 0.7685039370078741\n",
      "Epoch 7/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4604\n",
      "— train_f1: 0.7886178861788617 — val_f1: 0.7537437603993343\n",
      "Epoch 8/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4466\n",
      "— train_f1: 0.8031464300121017 — val_f1: 0.7600314712824547\n",
      "Epoch 9/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4451\n",
      "— train_f1: 0.7977886455453965 — val_f1: 0.7548117154811717\n",
      "Epoch 10/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4338\n",
      "— train_f1: 0.8117719190680565 — val_f1: 0.7745019920318724\n",
      "Epoch 11/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4119\n",
      "— train_f1: 0.8086627417998318 — val_f1: 0.7635467980295566\n",
      "Epoch 12/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4254\n",
      "— train_f1: 0.8087431693989071 — val_f1: 0.7619834710743801\n",
      "Epoch 13/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4132\n",
      "— train_f1: 0.8098547062539482 — val_f1: 0.7655737704918032\n",
      "Epoch 14/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4323\n",
      "— train_f1: 0.8018154311649017 — val_f1: 0.7527426160337554\n",
      "Epoch 15/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4072\n",
      "— train_f1: 0.8174668874172185 — val_f1: 0.7739340305711987\n",
      "Epoch 16/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4027\n",
      "— train_f1: 0.8131175110363674 — val_f1: 0.7645611156685809\n",
      "Epoch 17/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4112\n",
      "— train_f1: 0.8214581607290803 — val_f1: 0.768480909829407\n",
      "Epoch 18/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4150\n",
      "— train_f1: 0.8185053380782918 — val_f1: 0.7689795918367347\n",
      "Epoch 19/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4079\n",
      "— train_f1: 0.8281793979111203 — val_f1: 0.7754777070063695\n",
      "Epoch 20/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.3940\n",
      "— train_f1: 0.8283445326817348 — val_f1: 0.7765451664025357\n",
      "Epoch 21/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4003\n",
      "— train_f1: 0.815993121238177 — val_f1: 0.7654530059271804\n",
      "Epoch 22/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.3993\n",
      "— train_f1: 0.8194830164494766 — val_f1: 0.7630252100840336\n",
      "Epoch 23/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4022\n",
      "— train_f1: 0.8116005233318796 — val_f1: 0.7510841283607979\n",
      "Epoch 24/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.4081\n",
      "— train_f1: 0.8245946515055802 — val_f1: 0.7659222497932174\n",
      "Epoch 25/25\n",
      "189/189 [==============================] - 1s 3ms/step - loss: 0.3912\n",
      "— train_f1: 0.8340881020996295 — val_f1: 0.7790322580645161\n",
      "---- Starting fold 2 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.6864\n",
      "— train_f1: 0.741748349669934 — val_f1: 0.7144019528071603\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.5307\n",
      "— train_f1: 0.7672623883021933 — val_f1: 0.7436940602115542\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4886\n",
      "— train_f1: 0.7790339157245633 — val_f1: 0.7514356029532404\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4666\n",
      "— train_f1: 0.7883391500718538 — val_f1: 0.7544715447154472\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4627\n",
      "— train_f1: 0.7934052513739059 — val_f1: 0.7613636363636364\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4567\n",
      "— train_f1: 0.7959012965286492 — val_f1: 0.7570715474209652\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4445\n",
      "— train_f1: 0.7840210711150132 — val_f1: 0.7419635099913119\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4383\n",
      "— train_f1: 0.7894852135815992 — val_f1: 0.7364746945898779\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4380\n",
      "— train_f1: 0.8023926511429182 — val_f1: 0.7561181434599156\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4296\n",
      "— train_f1: 0.800767099936075 — val_f1: 0.751892346509672\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4421\n",
      "— train_f1: 0.7999131001520747 — val_f1: 0.745674740484429\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4217\n",
      "— train_f1: 0.8020565552699229 — val_f1: 0.7588532883642495\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4274\n",
      "— train_f1: 0.818936877076412 — val_f1: 0.7653311529026982\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4169\n",
      "— train_f1: 0.8180482686253935 — val_f1: 0.7601659751037344\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4233\n",
      "— train_f1: 0.8243048403707517 — val_f1: 0.759124087591241\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4148\n",
      "— train_f1: 0.8081204977079242 — val_f1: 0.7392055267702936\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4183\n",
      "— train_f1: 0.8132295719844358 — val_f1: 0.7519181585677749\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4136\n",
      "— train_f1: 0.8167922497308935 — val_f1: 0.751269035532995\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4042\n",
      "— train_f1: 0.8209083119108825 — val_f1: 0.7448979591836735\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4080\n",
      "— train_f1: 0.8174773999139046 — val_f1: 0.7465753424657534\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4027\n",
      "— train_f1: 0.8249735449735449 — val_f1: 0.7554438860971525\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3908\n",
      "— train_f1: 0.8190351451648112 — val_f1: 0.740418118466899\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4076\n",
      "— train_f1: 0.8260038240917781 — val_f1: 0.751892346509672\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4147\n",
      "— train_f1: 0.827247490924621 — val_f1: 0.754653130287648\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3807\n",
      "— train_f1: 0.8174637999122423 — val_f1: 0.7421052631578948\n",
      "---- Starting fold 3 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.6741\n",
      "— train_f1: 0.71813361611877 — val_f1: 0.715008431703204\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.5292\n",
      "— train_f1: 0.7659661293613549 — val_f1: 0.7567567567567567\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4963\n",
      "— train_f1: 0.7797716150081565 — val_f1: 0.7629204265791631\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4700\n",
      "— train_f1: 0.7792927141031103 — val_f1: 0.7577319587628866\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4656\n",
      "— train_f1: 0.7900295732995353 — val_f1: 0.7585034013605442\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4574\n",
      "— train_f1: 0.7910510764035458 — val_f1: 0.7671464860287891\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4462\n",
      "— train_f1: 0.7835772002620659 — val_f1: 0.751099384344767\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4320\n",
      "— train_f1: 0.7998328458002507 — val_f1: 0.7682008368200837\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4542\n",
      "— train_f1: 0.7816245006657789 — val_f1: 0.7455197132616487\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4490\n",
      "— train_f1: 0.8095139607032058 — val_f1: 0.7739783152627189\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4186\n",
      "— train_f1: 0.8006068487212831 — val_f1: 0.7552447552447552\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4402\n",
      "— train_f1: 0.8107308829742291 — val_f1: 0.7670068027210885\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4301\n",
      "— train_f1: 0.8042396712091714 — val_f1: 0.76\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4317\n",
      "— train_f1: 0.8158449220396122 — val_f1: 0.7633587786259541\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4212\n",
      "— train_f1: 0.8023689405571396 — val_f1: 0.7526501766784451\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4165\n",
      "— train_f1: 0.8253175098896522 — val_f1: 0.7644593461860856\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4202\n",
      "— train_f1: 0.8185689948892675 — val_f1: 0.7583834909716253\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4069\n",
      "— train_f1: 0.8131062729036431 — val_f1: 0.7580225498699046\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4240\n",
      "— train_f1: 0.8186706818670682 — val_f1: 0.7556325823223571\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4112\n",
      "— train_f1: 0.8273075287111868 — val_f1: 0.7538461538461538\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4081\n",
      "— train_f1: 0.8052584670231729 — val_f1: 0.7430117222723175\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4029\n",
      "— train_f1: 0.8147336110502083 — val_f1: 0.7428571428571428\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4076\n",
      "— train_f1: 0.8238599524529933 — val_f1: 0.7534965034965035\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4111\n",
      "— train_f1: 0.8303590625671898 — val_f1: 0.7547826086956522\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4123\n",
      "— train_f1: 0.8257314974182445 — val_f1: 0.7550130775937227\n",
      "---- Starting fold 4 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.6833\n",
      "— train_f1: 0.6551958342766584 — val_f1: 0.6386861313868613\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.5793\n",
      "— train_f1: 0.7560826006951544 — val_f1: 0.7459283387622151\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.5024\n",
      "— train_f1: 0.7666112956810631 — val_f1: 0.7537437603993343\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4679\n",
      "— train_f1: 0.7699914015477213 — val_f1: 0.7527993109388458\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4700\n",
      "— train_f1: 0.7865595942519019 — val_f1: 0.7601351351351352\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4742\n",
      "— train_f1: 0.7835451216885635 — val_f1: 0.7587982832618027\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4425\n",
      "— train_f1: 0.7942702927133071 — val_f1: 0.7697423108894429\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4409\n",
      "— train_f1: 0.8040057224606582 — val_f1: 0.766966475878986\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4479\n",
      "— train_f1: 0.7975563513798188 — val_f1: 0.7611064543168484\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4447\n",
      "— train_f1: 0.802944269190326 — val_f1: 0.7666666666666667\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4315\n",
      "— train_f1: 0.8062276456974542 — val_f1: 0.7636669470142977\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4500\n",
      "— train_f1: 0.8075980392156862 — val_f1: 0.774613506916192\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4257\n",
      "— train_f1: 0.8007695596408722 — val_f1: 0.7649063032367973\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4203\n",
      "— train_f1: 0.8102650399663441 — val_f1: 0.7698744769874478\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4329\n",
      "— train_f1: 0.8191446028513238 — val_f1: 0.7764326069410814\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4278\n",
      "— train_f1: 0.80694236125991 — val_f1: 0.7639484978540773\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4290\n",
      "— train_f1: 0.8054357204486625 — val_f1: 0.769098712446352\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4192\n",
      "— train_f1: 0.8197335553705246 — val_f1: 0.768079800498753\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4103\n",
      "— train_f1: 0.8232124352331606 — val_f1: 0.7701149425287356\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4169\n",
      "— train_f1: 0.8097392803275155 — val_f1: 0.758147512864494\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4181\n",
      "— train_f1: 0.8132245598969514 — val_f1: 0.7650085763293308\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3987\n",
      "— train_f1: 0.83083771752327 — val_f1: 0.7763578274760383\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4169\n",
      "— train_f1: 0.8093587521663778 — val_f1: 0.7513043478260869\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4154\n",
      "— train_f1: 0.8187407250370998 — val_f1: 0.7585034013605442\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4030\n",
      "— train_f1: 0.8313725490196078 — val_f1: 0.7687242798353909\n",
      "---- Starting fold 5 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.6694\n",
      "— train_f1: 0.7124949454104327 — val_f1: 0.7112211221122112\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.5456\n",
      "— train_f1: 0.7502552583214214 — val_f1: 0.7539094650205761\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4998\n",
      "— train_f1: 0.7602754016273732 — val_f1: 0.7455621301775147\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4820\n",
      "— train_f1: 0.7706422018348623 — val_f1: 0.7554806070826307\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4572\n",
      "— train_f1: 0.7786197010034814 — val_f1: 0.766804979253112\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4712\n",
      "— train_f1: 0.7839009287925696 — val_f1: 0.7730673316708231\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4510\n",
      "— train_f1: 0.7887147335423198 — val_f1: 0.7731092436974789\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4520\n",
      "— train_f1: 0.7807650273224044 — val_f1: 0.7622377622377623\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4549\n",
      "— train_f1: 0.7965925618117597 — val_f1: 0.7793505412156537\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4487\n",
      "— train_f1: 0.7948717948717948 — val_f1: 0.7807757166947723\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4293\n",
      "— train_f1: 0.7928235796668089 — val_f1: 0.7712305025996534\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4372\n",
      "— train_f1: 0.8088448026451746 — val_f1: 0.7960033305578685\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4346\n",
      "— train_f1: 0.796972972972973 — val_f1: 0.7741935483870969\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4150\n",
      "— train_f1: 0.8077003557229545 — val_f1: 0.7866666666666665\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4134\n",
      "— train_f1: 0.8165100122599102 — val_f1: 0.7941176470588235\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4173\n",
      "— train_f1: 0.8125533731853117 — val_f1: 0.7783505154639175\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4232\n",
      "— train_f1: 0.813237774030354 — val_f1: 0.7774030354131535\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4264\n",
      "— train_f1: 0.8207024029574862 — val_f1: 0.7881773399014779\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4075\n",
      "— train_f1: 0.8213689482470785 — val_f1: 0.7939949958298582\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4239\n",
      "— train_f1: 0.8202995008319468 — val_f1: 0.7980132450331126\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4293\n",
      "— train_f1: 0.8234313112361893 — val_f1: 0.7943615257048092\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4114\n",
      "— train_f1: 0.8152920962199313 — val_f1: 0.7715996578272026\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4254\n",
      "— train_f1: 0.8194207836456557 — val_f1: 0.7751277683134582\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.3889\n",
      "— train_f1: 0.8317891702697139 — val_f1: 0.7940691927512357\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.4119\n",
      "— train_f1: 0.831179658190913 — val_f1: 0.7886855241264561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "metrics = []\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X=X, y=y)):\n",
    "    print('---- Starting fold %d ----'%(k_fold+1))\n",
    "    \n",
    "    x_train, y_train = X[tr_inds], y[tr_inds]\n",
    "    x_val, y_val = X[val_inds], y[val_inds]\n",
    "    conv_model = get_model()\n",
    "    conv_model.compile(loss='binary_crossentropy', optimizer= \"adam\", metrics=[])    \n",
    "    m = Metrics(train=(x_train,y_train), validation=(x_val, y_val))\n",
    "    conv_model.fit(x=x_train, y=y_train, batch_size=32, epochs=25, \n",
    "               callbacks=[m])\n",
    "    metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m in metrics:\n",
    "    scores.append(m.val_f1s[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.767461, 0.748264, 0.769231, 0.75616, 0.782824]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764788"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginally better as averaging?? Train model on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6483\n",
      "Epoch 2/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5194\n",
      "Epoch 3/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4946\n",
      "Epoch 4/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4700\n",
      "Epoch 5/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4622\n",
      "Epoch 6/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4576\n",
      "Epoch 7/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4531\n",
      "Epoch 8/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4162\n",
      "Epoch 9/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4315\n",
      "Epoch 10/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4332\n",
      "Epoch 11/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4262\n",
      "Epoch 12/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4302\n",
      "Epoch 13/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4385\n",
      "Epoch 14/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4139\n",
      "Epoch 15/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4146\n",
      "Epoch 16/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4061\n",
      "Epoch 17/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4128\n",
      "Epoch 18/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4246\n",
      "Epoch 19/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4162\n",
      "Epoch 20/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4012\n",
      "Epoch 21/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3995\n",
      "Epoch 22/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4041\n",
      "Epoch 23/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4007\n",
      "Epoch 24/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4049\n",
      "Epoch 25/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f98527880>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = get_model()\n",
    "conv_model.compile(loss='binary_crossentropy', optimizer= \"adam\")    \n",
    "conv_model.fit(x=X, y=y, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_X(test, 'wordvec_concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = conv_model.predict(X_test)\n",
    "pred = pred.flatten().round()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\":test['id'], \"target\":pred.flatten().round().astype(int)})\n",
    "submission.to_csv('conv_net.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
