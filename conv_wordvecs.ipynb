{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional wordvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_train = pd.read_pickle('train_wordvec.pickle')\n",
    "wordvec_test = pd.read_pickle('test_wordvec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>wordvec</th>\n",
       "      <th>keyword_wordvec</th>\n",
       "      <th>wordvec_concat</th>\n",
       "      <th>wordvec_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[[-0.2820900082588196, 0.1519400030374527, -0....</td>\n",
       "      <td>[-2.0410312242232838, 0.1577752003302941, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[[0.3039900064468384, 0.20476000010967255, -0....</td>\n",
       "      <td>[-0.27185601989428204, 0.2042857458194097, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[[0.00997759960591793, -0.20995000004768372, -...</td>\n",
       "      <td>[0.07528745450756767, 0.11175614595413208, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[[-0.19686000049114227, 0.1157900020480156, -0...</td>\n",
       "      <td>[-1.3403782035623277, 1.2000715562275477, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[[-0.02556299977004528, 0.444240003824234, -0....</td>\n",
       "      <td>[-0.7245167245467504, -0.364056259393692, 0.52...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                       cleaned_text  \\\n",
       "0       1  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1       1             Forest fire near La Ronge Sask. Canada   \n",
       "2       1  All residents asked to 'shelter in place' are ...   \n",
       "3       1  people receive wildfires evacuation orders in ...   \n",
       "4       1  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                             wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                     keyword_wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                      wordvec_concat  \\\n",
       "0  [[-0.2820900082588196, 0.1519400030374527, -0....   \n",
       "1  [[0.3039900064468384, 0.20476000010967255, -0....   \n",
       "2  [[0.00997759960591793, -0.20995000004768372, -...   \n",
       "3  [[-0.19686000049114227, 0.1157900020480156, -0...   \n",
       "4  [[-0.02556299977004528, 0.444240003824234, -0....   \n",
       "\n",
       "                                       wordvec_tfidf  \n",
       "0  [-2.0410312242232838, 0.1577752003302941, -0.8...  \n",
       "1  [-0.27185601989428204, 0.2042857458194097, -1....  \n",
       "2  [0.07528745450756767, 0.11175614595413208, -0....  \n",
       "3  [-1.3403782035623277, 1.2000715562275477, 0.11...  \n",
       "4  [-0.7245167245467504, -0.364056259393692, 0.52...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(wordvec_train, on=['id'])\n",
    "test = test.merge(wordvec_test, on=['id'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = max(train['wordvec_concat'].apply(lambda x: x.shape[0]).max(),\n",
    "                test['wordvec_concat'].apply(lambda x: x.shape[0]).max())\n",
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def get_X(df, col):\n",
    "    X = concat = numpy.empty((0, max_words, 300))\n",
    "    for index, row in df.iterrows():\n",
    "        x = numpy.pad(row[col],((0,max_words - row[col].shape[0]),(0, 0)))\n",
    "        X = numpy.append(X, [x], axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "X = get_X(train, 'wordvec_concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7561, 33, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_model():\n",
    "    conv_model = tf.keras.Sequential([\\\n",
    "        tf.keras.layers.Dropout(0.4, input_shape=(max_words,300)),          \n",
    "        tf.keras.layers.Conv1D(filters=6, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Dropout(0.3),  \n",
    "        tf.keras.layers.Conv1D(filters=8, kernel_size=5, activation='relu'),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.2),                           \n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid'),\n",
    "    ])\n",
    "    return conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, train, validation):   \n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation = validation    \n",
    "        self.train = train        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):        \n",
    "        self.val_f1s = []\n",
    "        self.train_f1s = []\n",
    "             \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_targ = self.validation[1]   \n",
    "        val_predict = (np.asarray(self.model.predict(self.validation[0]))).round()        \n",
    "        \n",
    "        train_targ = self.train[1]   \n",
    "        train_predict = (np.asarray(self.model.predict(self.train[0]))).round()   \n",
    "        \n",
    "        val_f1 = f1_score(val_targ, val_predict)\n",
    "        train_f1 = f1_score(train_targ, train_predict)\n",
    "        self.val_f1s.append(round(val_f1, 6))\n",
    "        self.train_f1s.append(round(train_f1, 6))\n",
    "        \n",
    "        print(f'— train_f1: {train_f1} — val_f1: {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting fold 1 ----\n",
      "Epoch 1/100\n",
      "186/189 [============================>.] - ETA: 0s - loss: 0.5181— train_f1: 0.7958222404259677 — val_f1: 0.7596153846153846\n",
      "189/189 [==============================] - 4s 20ms/step - loss: 0.5163\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.4028— train_f1: 0.8401639344262295 — val_f1: 0.7768069896743447\n",
      "189/189 [==============================] - 5s 24ms/step - loss: 0.4028\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - ETA: 0s - loss: 0.3503— train_f1: 0.838279569892473 — val_f1: 0.748709122203098\n",
      "189/189 [==============================] - 5s 25ms/step - loss: 0.3503\n",
      "Epoch 4/100\n",
      "  3/189 [..............................] - ETA: 3s - loss: 0.2512"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "metrics = []\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X=X, y=y)):\n",
    "    print('---- Starting fold %d ----'%(k_fold+1))\n",
    "    \n",
    "    x_train, y_train = X[tr_inds], y[tr_inds]\n",
    "    x_val, y_val = X[val_inds], y[val_inds]\n",
    "    conv_model = get_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    conv_model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=[])    \n",
    "    m = Metrics(train=(x_train,y_train), validation=(x_val, y_val))\n",
    "    conv_model.fit(x=x_train, y=y_train, batch_size=32, epochs=25, \n",
    "               callbacks=[m])\n",
    "    metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m in metrics:\n",
    "    scores.append(m.val_f1s[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.767461, 0.748264, 0.769231, 0.75616, 0.782824]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764788"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginally better as averaging?? Train model on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.6483\n",
      "Epoch 2/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.5194\n",
      "Epoch 3/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4946\n",
      "Epoch 4/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4700\n",
      "Epoch 5/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4622\n",
      "Epoch 6/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4576\n",
      "Epoch 7/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4531\n",
      "Epoch 8/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4162\n",
      "Epoch 9/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4315\n",
      "Epoch 10/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4332\n",
      "Epoch 11/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4262\n",
      "Epoch 12/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4302\n",
      "Epoch 13/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4385\n",
      "Epoch 14/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4139\n",
      "Epoch 15/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4146\n",
      "Epoch 16/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4061\n",
      "Epoch 17/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4128\n",
      "Epoch 18/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4246\n",
      "Epoch 19/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4162\n",
      "Epoch 20/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4012\n",
      "Epoch 21/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.3995\n",
      "Epoch 22/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4041\n",
      "Epoch 23/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4007\n",
      "Epoch 24/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4049\n",
      "Epoch 25/25\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.4028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f98527880>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = get_model()\n",
    "conv_model.compile(loss='binary_crossentropy', optimizer= \"adam\")    \n",
    "conv_model.fit(x=X, y=y, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_X(test, 'wordvec_concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = conv_model.predict(X_test)\n",
    "pred = pred.flatten().round()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\":test['id'], \"target\":pred.flatten().round().astype(int)})\n",
    "submission.to_csv('conv_net.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try RNNs instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_rnn_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(16, dropout=0.1, input_shape=(max_words,300)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 16)                5072      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,153\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_rnn_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting fold 1 ----\n",
      "Epoch 1/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.7409\n",
      "— train_f1: 0.33575909661229614 — val_f1: 0.38040345821325644\n",
      "Epoch 2/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.6694\n",
      "— train_f1: 0.5455941639470149 — val_f1: 0.5429403202328967\n",
      "Epoch 3/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.6405\n",
      "— train_f1: 0.6517571884984025 — val_f1: 0.633855331841909\n",
      "Epoch 4/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.5936\n",
      "— train_f1: 0.6924838642515095 — val_f1: 0.6771523178807948\n",
      "Epoch 5/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.5369\n",
      "— train_f1: 0.7522531544161827 — val_f1: 0.726698262243286\n",
      "Epoch 6/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.5067\n",
      "— train_f1: 0.7553542009884681 — val_f1: 0.7168284789644013\n",
      "Epoch 7/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4829\n",
      "— train_f1: 0.7748193229364778 — val_f1: 0.7317436661698957\n",
      "Epoch 8/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.5115\n",
      "— train_f1: 0.7530095475300955 — val_f1: 0.7220394736842105\n",
      "Epoch 9/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4916\n",
      "— train_f1: 0.777080380643855 — val_f1: 0.7352472089314195\n",
      "Epoch 10/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4844\n",
      "— train_f1: 0.7738070646560629 — val_f1: 0.7386363636363635\n",
      "Epoch 11/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4651\n",
      "— train_f1: 0.7780758911460329 — val_f1: 0.7345724907063197\n",
      "Epoch 12/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4689\n",
      "— train_f1: 0.7924309712299671 — val_f1: 0.7449209932279908\n",
      "Epoch 13/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4540\n",
      "— train_f1: 0.7881694644284571 — val_f1: 0.744945567651633\n",
      "Epoch 14/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4609\n",
      "— train_f1: 0.7831768068599428 — val_f1: 0.7482014388489208\n",
      "Epoch 15/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4648\n",
      "— train_f1: 0.7883683360258482 — val_f1: 0.7450670876085241\n",
      "Epoch 16/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4445\n",
      "— train_f1: 0.7874975427560448 — val_f1: 0.7461538461538461\n",
      "Epoch 17/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4831\n",
      "— train_f1: 0.7856730213749277 — val_f1: 0.7354935945742276\n",
      "Epoch 18/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4511\n",
      "— train_f1: 0.7925294356475842 — val_f1: 0.7368421052631577\n",
      "Epoch 19/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4326\n",
      "— train_f1: 0.05915894511760513 — val_f1: 0.06818181818181818\n",
      "Epoch 20/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.5004\n",
      "— train_f1: 0.7751004016064257 — val_f1: 0.723044397463002\n",
      "Epoch 21/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4696\n",
      "— train_f1: 0.7730818066388536 — val_f1: 0.7431770468859341\n",
      "Epoch 22/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4455\n",
      "— train_f1: 0.7906786590351597 — val_f1: 0.7443729903536976\n",
      "Epoch 23/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4344\n",
      "— train_f1: 0.8011718749999999 — val_f1: 0.7354740061162081\n",
      "Epoch 24/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4284\n",
      "— train_f1: 0.7928034796362198 — val_f1: 0.7476340694006309\n",
      "Epoch 25/25\n",
      "189/189 [==============================] - 1s 4ms/step - loss: 0.4409\n",
      "— train_f1: 0.802469135802469 — val_f1: 0.7480314960629922\n",
      "---- Starting fold 2 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.7175\n",
      "— train_f1: 0.5712833545108005 — val_f1: 0.5599999999999999\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5277\n",
      "— train_f1: 0.6835443037974683 — val_f1: 0.6616399622997171\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5011\n",
      "— train_f1: 0.7728178557194101 — val_f1: 0.7376788553259142\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4599\n",
      "— train_f1: 0.7841666666666667 — val_f1: 0.7416666666666666\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4609\n",
      "— train_f1: 0.7948511665325825 — val_f1: 0.7472178060413354\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4334\n",
      "— train_f1: 0.7776560788608982 — val_f1: 0.7166521360069749\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4317\n",
      "— train_f1: 0.7767288693743138 — val_f1: 0.7229551451187336\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4204\n",
      "— train_f1: 0.8035714285714286 — val_f1: 0.7533112582781457\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4122\n",
      "— train_f1: 0.7469990766389659 — val_f1: 0.6884939195509822\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4269\n",
      "— train_f1: 0.8053322048243758 — val_f1: 0.7318718381112985\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4112\n",
      "— train_f1: 0.8152111599464934 — val_f1: 0.7617625093353249\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.4088\n",
      "— train_f1: 0.822387443205287 — val_f1: 0.7452596867271228\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3961\n",
      "— train_f1: 0.8051470588235294 — val_f1: 0.7514367816091955\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3897\n",
      "— train_f1: 0.8278560250391237 — val_f1: 0.7550077041602464\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3935\n",
      "— train_f1: 0.8279201129715552 — val_f1: 0.7465362673186633\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3920\n",
      "— train_f1: 0.8419991938734381 — val_f1: 0.752411575562701\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3944\n",
      "— train_f1: 0.7690641247833622 — val_f1: 0.7152777777777779\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.4095\n",
      "— train_f1: 0.8282537067545304 — val_f1: 0.7400662251655629\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3816\n",
      "— train_f1: 0.829088080886642 — val_f1: 0.7478927203065134\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3831\n",
      "— train_f1: 0.7818554821062229 — val_f1: 0.6844526218951242\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3749\n",
      "— train_f1: 0.8250909869406979 — val_f1: 0.7246127366609294\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3668\n",
      "— train_f1: 0.8287904599659284 — val_f1: 0.7234782608695652\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3667\n",
      "— train_f1: 0.7404778802933524 — val_f1: 0.6498054474708171\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3678\n",
      "— train_f1: 0.8347124973477615 — val_f1: 0.7294520547945205\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3635\n",
      "— train_f1: 0.8470260592798887 — val_f1: 0.7423167848699764\n",
      "---- Starting fold 3 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.7553\n",
      "— train_f1: 0.0993745656706046 — val_f1: 0.10136986301369863\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.6729\n",
      "— train_f1: 0.20344491387715305 — val_f1: 0.17357512953367873\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.6518\n",
      "— train_f1: 0.6727646070561882 — val_f1: 0.6511289147851421\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5729\n",
      "— train_f1: 0.6579194001874414 — val_f1: 0.6322701688555347\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5197\n",
      "— train_f1: 0.7612003381234151 — val_f1: 0.6933560477001705\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4900\n",
      "— train_f1: 0.7698887938408896 — val_f1: 0.7012089810017271\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4558\n",
      "— train_f1: 0.8066776586974443 — val_f1: 0.7135761589403973\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4355\n",
      "— train_f1: 0.8183062781146099 — val_f1: 0.7069767441860464\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4225\n",
      "— train_f1: 0.8199881959472752 — val_f1: 0.726144297905353\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4173\n",
      "— train_f1: 0.8362779740871613 — val_f1: 0.7165109034267912\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3932\n",
      "— train_f1: 0.8156879554222032 — val_f1: 0.6910994764397905\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3816\n",
      "— train_f1: 0.8392338943702844 — val_f1: 0.7337909992372235\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3780\n",
      "— train_f1: 0.8364544319600499 — val_f1: 0.7164685908319185\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3760\n",
      "— train_f1: 0.8519024390243901 — val_f1: 0.7281177381874516\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3572\n",
      "— train_f1: 0.8481797056545315 — val_f1: 0.727833461835004\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3635\n",
      "— train_f1: 0.8594267888477286 — val_f1: 0.7274119448698315\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3536\n",
      "— train_f1: 0.8665993945509586 — val_f1: 0.731785428342674\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3464\n",
      "— train_f1: 0.8685852284161802 — val_f1: 0.7244979919678716\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3496\n",
      "— train_f1: 0.8588088296543108 — val_f1: 0.7222222222222223\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3410\n",
      "— train_f1: 0.8754762382193705 — val_f1: 0.7335473515248797\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3385\n",
      "— train_f1: 0.8651894802236488 — val_f1: 0.7304785894206548\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3354\n",
      "— train_f1: 0.8471324296141814 — val_f1: 0.7072758037225043\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3467\n",
      "— train_f1: 0.8795853269537479 — val_f1: 0.7320574162679427\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3178\n",
      "— train_f1: 0.8868706811451136 — val_f1: 0.7358490566037735\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3334\n",
      "— train_f1: 0.8837304011402972 — val_f1: 0.7333880229696472\n",
      "---- Starting fold 4 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 2s 4ms/step - loss: 0.6454\n",
      "— train_f1: 0.7250599931436407 — val_f1: 0.7171097477845944\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5033\n",
      "— train_f1: 0.7566006600660066 — val_f1: 0.7417218543046357\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4899\n",
      "— train_f1: 0.7625390218522373 — val_f1: 0.7435254803675856\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4721\n",
      "— train_f1: 0.7610238761023876 — val_f1: 0.7299651567944251\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4532\n",
      "— train_f1: 0.7849393746011487 — val_f1: 0.7529610829103216\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4353\n",
      "— train_f1: 0.7666300768386389 — val_f1: 0.7320490367775832\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4251\n",
      "— train_f1: 0.805127178049269 — val_f1: 0.7521912350597609\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4120\n",
      "— train_f1: 0.7554446460980035 — val_f1: 0.7136322049405307\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4091\n",
      "— train_f1: 0.7879973907371168 — val_f1: 0.7375762859633826\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4016\n",
      "— train_f1: 0.8158961881589618 — val_f1: 0.7709677419354839\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4056\n",
      "— train_f1: 0.7612314709236032 — val_f1: 0.7151956323930846\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4063\n",
      "— train_f1: 0.8253343823760819 — val_f1: 0.7712933753943217\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3898\n",
      "— train_f1: 0.8124999999999999 — val_f1: 0.7491582491582491\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3896\n",
      "— train_f1: 0.817972831765935 — val_f1: 0.7546218487394957\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3840\n",
      "— train_f1: 0.8142116950407107 — val_f1: 0.7649226234340456\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3902\n",
      "— train_f1: 0.8385080225046885 — val_f1: 0.7589063794531898\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3895\n",
      "— train_f1: 0.8420833333333333 — val_f1: 0.7537437603993343\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3884\n",
      "— train_f1: 0.8296961916987592 — val_f1: 0.7347639484978541\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3768\n",
      "— train_f1: 0.839258114374034 — val_f1: 0.7581903276131045\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3444\n",
      "— train_f1: 0.8286309411096384 — val_f1: 0.754688672168042\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3600\n",
      "— train_f1: 0.840421052631579 — val_f1: 0.7500000000000001\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3618\n",
      "— train_f1: 0.817966903073286 — val_f1: 0.7514450867052024\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3689\n",
      "— train_f1: 0.8300738809213386 — val_f1: 0.7441048034934498\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3412\n",
      "— train_f1: 0.8220562390158173 — val_f1: 0.7246636771300448\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3730\n",
      "— train_f1: 0.8342385400825548 — val_f1: 0.7357330992098332\n",
      "---- Starting fold 5 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.6268\n",
      "— train_f1: 0.732370788867964 — val_f1: 0.714527027027027\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.5081\n",
      "— train_f1: 0.7416757344940154 — val_f1: 0.7099035933391762\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4758\n",
      "— train_f1: 0.7761692650334074 — val_f1: 0.7535795026375283\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4763\n",
      "— train_f1: 0.7825285661629193 — val_f1: 0.7606901725431359\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4412\n",
      "— train_f1: 0.785563528915154 — val_f1: 0.7341337907375644\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4402\n",
      "— train_f1: 0.7793367346938775 — val_f1: 0.7351164797238999\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4261\n",
      "— train_f1: 0.8133012820512819 — val_f1: 0.7493956486704271\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4210\n",
      "— train_f1: 0.788444284945272 — val_f1: 0.7585206671501087\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4299\n",
      "— train_f1: 0.8193108974358975 — val_f1: 0.7622097678142514\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4251\n",
      "— train_f1: 0.8068524096385543 — val_f1: 0.7565938206480785\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4117\n",
      "— train_f1: 0.8205025927403271 — val_f1: 0.7584\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.4114\n",
      "— train_f1: 0.8217801047120418 — val_f1: 0.7372881355932203\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 1s 5ms/step - loss: 0.3993\n",
      "— train_f1: 0.7954644570431748 — val_f1: 0.7274336283185842\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3995\n",
      "— train_f1: 0.7851851851851852 — val_f1: 0.7197802197802197\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3919\n",
      "— train_f1: 0.8300487804878048 — val_f1: 0.7580266249021144\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3797\n",
      "— train_f1: 0.8009687362395419 — val_f1: 0.7193460490463215\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3799\n",
      "— train_f1: 0.8300202839756592 — val_f1: 0.746317512274959\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3998\n",
      "— train_f1: 0.8398373983739837 — val_f1: 0.7595762021189895\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3693\n",
      "— train_f1: 0.8217800131204899 — val_f1: 0.725135623869801\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3768\n",
      "— train_f1: 0.8339085418464194 — val_f1: 0.7291849255039439\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3739\n",
      "— train_f1: 0.8414143552826593 — val_f1: 0.7358490566037736\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3538\n",
      "— train_f1: 0.8505122308174786 — val_f1: 0.7404902789518174\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3599\n",
      "— train_f1: 0.8511253355358248 — val_f1: 0.7487437185929648\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3516\n",
      "— train_f1: 0.8439086294416244 — val_f1: 0.7383015597920278\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 1s 4ms/step - loss: 0.3542\n",
      "— train_f1: 0.842706131078224 — val_f1: 0.725085910652921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "metrics = []\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X=X, y=y)):\n",
    "    print('---- Starting fold %d ----'%(k_fold+1))\n",
    "    \n",
    "    x_train, y_train = X[tr_inds], y[tr_inds]\n",
    "    x_val, y_val = X[val_inds], y[val_inds]\n",
    "    model = get_rnn_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=[])    \n",
    "    m = Metrics(train=(x_train,y_train), validation=(x_val, y_val))\n",
    "    model.fit(x=x_train, y=y_train, batch_size=32, epochs=25, \n",
    "               callbacks=[m])\n",
    "    metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m in metrics:\n",
    "    scores.append(m.val_f1s[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.748031, 0.742317, 0.733388, 0.735733, 0.725086]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7369110000000001"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_gru_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.GRU(8, dropout=0.35, input_shape=(max_words,300)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 8)                 7440      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 7,481\n",
      "Trainable params: 7,465\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_gru_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting fold 1 ----\n",
      "Epoch 1/25\n",
      "189/189 [==============================] - 2s 7ms/step - loss: 0.6865\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 2/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.6802\n",
      "— train_f1: 0.0007716049382716049 — val_f1: 0.0\n",
      "Epoch 3/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.6774\n",
      "— train_f1: 0.6020230205790024 — val_f1: 0.602510460251046\n",
      "Epoch 4/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.5398\n",
      "— train_f1: 0.7750105529759392 — val_f1: 0.7397489539748955\n",
      "Epoch 5/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.4534\n",
      "— train_f1: 0.7776809067131648 — val_f1: 0.7398444252376837\n",
      "Epoch 6/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.4320\n",
      "— train_f1: 0.8082691528171869 — val_f1: 0.7609912070343724\n",
      "Epoch 7/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.4191\n",
      "— train_f1: 0.7961921246213761 — val_f1: 0.75\n",
      "Epoch 8/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.4015\n",
      "— train_f1: 0.814625850340136 — val_f1: 0.7669172932330828\n",
      "Epoch 9/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3953\n",
      "— train_f1: 0.8273748723186924 — val_f1: 0.7601593625498008\n",
      "Epoch 10/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3962\n",
      "— train_f1: 0.8257504247687371 — val_f1: 0.7602339181286549\n",
      "Epoch 11/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3829\n",
      "— train_f1: 0.8178067318132464 — val_f1: 0.7586805555555556\n",
      "Epoch 12/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3888\n",
      "— train_f1: 0.8294051627384962 — val_f1: 0.7580174927113702\n",
      "Epoch 13/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3691\n",
      "— train_f1: 0.8399615754082613 — val_f1: 0.7624060150375941\n",
      "Epoch 14/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3491\n",
      "— train_f1: 0.8465520811762269 — val_f1: 0.7698607698607699\n",
      "Epoch 15/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3613\n",
      "— train_f1: 0.8418821534548537 — val_f1: 0.7706576728499158\n",
      "Epoch 16/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3633\n",
      "— train_f1: 0.8511979823455234 — val_f1: 0.7676935886761032\n",
      "Epoch 17/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3644\n",
      "— train_f1: 0.8544814738149452 — val_f1: 0.7701149425287356\n",
      "Epoch 18/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3650\n",
      "— train_f1: 0.8619556285949056 — val_f1: 0.7633711507293354\n",
      "Epoch 19/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3301\n",
      "— train_f1: 0.8653028154749849 — val_f1: 0.773055332798717\n",
      "Epoch 20/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3433\n",
      "— train_f1: 0.8678861788617885 — val_f1: 0.7756410256410257\n",
      "Epoch 21/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3254\n",
      "— train_f1: 0.8541754980924121 — val_f1: 0.765704584040747\n",
      "Epoch 22/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3418\n",
      "— train_f1: 0.8473990934599612 — val_f1: 0.7667238421955404\n",
      "Epoch 23/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3437\n",
      "— train_f1: 0.8659147869674186 — val_f1: 0.7674418604651163\n",
      "Epoch 24/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3301\n",
      "— train_f1: 0.8745476477683957 — val_f1: 0.7641509433962265\n",
      "Epoch 25/25\n",
      "189/189 [==============================] - 1s 7ms/step - loss: 0.3327\n",
      "— train_f1: 0.8702610020956374 — val_f1: 0.7538574577516531\n",
      "---- Starting fold 2 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 4s 11ms/step - loss: 0.6895\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6753\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6647\n",
      "— train_f1: 0.686941829592083 — val_f1: 0.6516192345436703\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4568\n",
      "— train_f1: 0.7964750314729333 — val_f1: 0.7487266553480475\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4213\n",
      "— train_f1: 0.7803583278035833 — val_f1: 0.7330960854092528\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4174\n",
      "— train_f1: 0.7819481680071493 — val_f1: 0.7279279279279279\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4039\n",
      "— train_f1: 0.8036450423085268 — val_f1: 0.7421602787456446\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4038\n",
      "— train_f1: 0.8132103795839589 — val_f1: 0.7452667814113598\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3961\n",
      "— train_f1: 0.8272066050717516 — val_f1: 0.7770800627943486\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3938\n",
      "— train_f1: 0.8264119601328904 — val_f1: 0.7628524046434494\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3812\n",
      "— train_f1: 0.8324628364805142 — val_f1: 0.7637231503579951\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3715\n",
      "— train_f1: 0.8404932378679396 — val_f1: 0.7724358974358975\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3663\n",
      "— train_f1: 0.8477249747219413 — val_f1: 0.7722132471728596\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3781\n",
      "— train_f1: 0.8255965292841647 — val_f1: 0.748709122203098\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3693\n",
      "— train_f1: 0.8489180067500497 — val_f1: 0.7736298649722002\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3569\n",
      "— train_f1: 0.8529173419773095 — val_f1: 0.775974025974026\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3690\n",
      "— train_f1: 0.8557013118062563 — val_f1: 0.7697314890154596\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3497\n",
      "— train_f1: 0.8553770086526575 — val_f1: 0.7734439834024897\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3563\n",
      "— train_f1: 0.8508827908955542 — val_f1: 0.756388415672913\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3521\n",
      "— train_f1: 0.858581619806966 — val_f1: 0.7555178268251274\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3317\n",
      "— train_f1: 0.8627940870289402 — val_f1: 0.7581589958158996\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3377\n",
      "— train_f1: 0.8664404072669195 — val_f1: 0.7721518987341771\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3469\n",
      "— train_f1: 0.8699021207177814 — val_f1: 0.7694805194805195\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3443\n",
      "— train_f1: 0.8713438330947023 — val_f1: 0.7638436482084691\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3326\n",
      "— train_f1: 0.8721653622315874 — val_f1: 0.7613005551149881\n",
      "---- Starting fold 3 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 3s 11ms/step - loss: 0.6875\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6805\n",
      "— train_f1: 0.0007716049382716049 — val_f1: 0.0\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6535\n",
      "— train_f1: 0.7530500631047539 — val_f1: 0.7447346251053075\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4663\n",
      "— train_f1: 0.7885453413571281 — val_f1: 0.7660283097418819\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4390\n",
      "— train_f1: 0.7953241232731137 — val_f1: 0.7673819742489271\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4258\n",
      "— train_f1: 0.8044971892567145 — val_f1: 0.7796327212020033\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4169\n",
      "— train_f1: 0.8018807437486642 — val_f1: 0.7700258397932815\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3994\n",
      "— train_f1: 0.7946526408064869 — val_f1: 0.7658450704225352\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3834\n",
      "— train_f1: 0.818738130407259 — val_f1: 0.7732656514382402\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3953\n",
      "— train_f1: 0.8154490799781381 — val_f1: 0.7644508670520231\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3864\n",
      "— train_f1: 0.8305256748528517 — val_f1: 0.778050778050778\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3706\n",
      "— train_f1: 0.8235546958951214 — val_f1: 0.7694974003466205\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3714\n",
      "— train_f1: 0.8370659543866859 — val_f1: 0.780608052588332\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3742\n",
      "— train_f1: 0.8366666666666668 — val_f1: 0.7723785166240409\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3628\n",
      "— train_f1: 0.8398231951168175 — val_f1: 0.7689684569479966\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3664\n",
      "— train_f1: 0.8375634517766497 — val_f1: 0.7755102040816326\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3722\n",
      "— train_f1: 0.8447048974466304 — val_f1: 0.7753378378378379\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3545\n",
      "— train_f1: 0.8597536750099325 — val_f1: 0.7697160883280757\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3516\n",
      "— train_f1: 0.8452607135317711 — val_f1: 0.7771135781383434\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3544\n",
      "— train_f1: 0.8504633529907328 — val_f1: 0.7696245733788396\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3605\n",
      "— train_f1: 0.8594539939332658 — val_f1: 0.7782290820471163\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3414\n",
      "— train_f1: 0.8546438983756767 — val_f1: 0.7750631844987363\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3292\n",
      "— train_f1: 0.8502456740012817 — val_f1: 0.7644521138912855\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3522\n",
      "— train_f1: 0.8453563714902808 — val_f1: 0.7559055118110236\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3424\n",
      "— train_f1: 0.8628189042241741 — val_f1: 0.7724957555178268\n",
      "---- Starting fold 4 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 3s 11ms/step - loss: 0.6871\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6737\n",
      "— train_f1: 0.002313030069390902 — val_f1: 0.0030816640986132513\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.5010\n",
      "— train_f1: 0.7408944213923467 — val_f1: 0.7302752293577981\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4366\n",
      "— train_f1: 0.784526391901663 — val_f1: 0.7704678362573099\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4258\n",
      "— train_f1: 0.807885737276202 — val_f1: 0.7797427652733119\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4223\n",
      "— train_f1: 0.8119438402214751 — val_f1: 0.7832278481012658\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4189\n",
      "— train_f1: 0.8167215815485998 — val_f1: 0.7815333882934872\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4007\n",
      "— train_f1: 0.8216127036502372 — val_f1: 0.7773212818405917\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4011\n",
      "— train_f1: 0.8272822665267577 — val_f1: 0.7720773759461733\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4022\n",
      "— train_f1: 0.8278912997682748 — val_f1: 0.7776838546069316\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3900\n",
      "— train_f1: 0.8310615448161918 — val_f1: 0.7782357790601814\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3899\n",
      "— train_f1: 0.8388388388388388 — val_f1: 0.7829581993569132\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3714\n",
      "— train_f1: 0.8454194596790575 — val_f1: 0.7860048820179008\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3704\n",
      "— train_f1: 0.8422296631869214 — val_f1: 0.7772511848341233\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3864\n",
      "— train_f1: 0.8396785109983079 — val_f1: 0.7661016949152543\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3650\n",
      "— train_f1: 0.8534095549203756 — val_f1: 0.782464846980976\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3615\n",
      "— train_f1: 0.8279334500875657 — val_f1: 0.7450628366247756\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3605\n",
      "— train_f1: 0.8600995024875621 — val_f1: 0.7770700636942676\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3551\n",
      "— train_f1: 0.8622366288492707 — val_f1: 0.7828894269572237\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3479\n",
      "— train_f1: 0.8591108328115216 — val_f1: 0.7705192629815745\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3498\n",
      "— train_f1: 0.8656482569526048 — val_f1: 0.7819314641744548\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3567\n",
      "— train_f1: 0.8648424543946932 — val_f1: 0.7802013422818792\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3381\n",
      "— train_f1: 0.874083129584352 — val_f1: 0.7823960880195598\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3374\n",
      "— train_f1: 0.8706519475109352 — val_f1: 0.7733782645324346\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3643\n",
      "— train_f1: 0.8534076296613802 — val_f1: 0.7666666666666666\n",
      "---- Starting fold 5 ----\n",
      "Epoch 1/25\n",
      "190/190 [==============================] - 3s 11ms/step - loss: 0.6875\n",
      "— train_f1: 0.0 — val_f1: 0.0\n",
      "Epoch 2/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.6476\n",
      "— train_f1: 0.1911049339819319 — val_f1: 0.14835948644793154\n",
      "Epoch 3/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4547\n",
      "— train_f1: 0.6579345088161209 — val_f1: 0.6531440162271805\n",
      "Epoch 4/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4354\n",
      "— train_f1: 0.7906880066514238 — val_f1: 0.7677100494233938\n",
      "Epoch 5/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4296\n",
      "— train_f1: 0.7724444444444445 — val_f1: 0.7586206896551724\n",
      "Epoch 6/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4043\n",
      "— train_f1: 0.8043569333891915 — val_f1: 0.783761391880696\n",
      "Epoch 7/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.4141\n",
      "— train_f1: 0.8015547397970201 — val_f1: 0.7789291882556131\n",
      "Epoch 8/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3925\n",
      "— train_f1: 0.7984327383543752 — val_f1: 0.7702936096718481\n",
      "Epoch 9/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3901\n",
      "— train_f1: 0.8154362416107381 — val_f1: 0.7813021702838063\n",
      "Epoch 10/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3971\n",
      "— train_f1: 0.8201680672268907 — val_f1: 0.7813798836242727\n",
      "Epoch 11/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3779\n",
      "— train_f1: 0.8210481465700894 — val_f1: 0.785774767146486\n",
      "Epoch 12/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3783\n",
      "— train_f1: 0.8141670310450372 — val_f1: 0.7798085291557876\n",
      "Epoch 13/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3811\n",
      "— train_f1: 0.8392359729407084 — val_f1: 0.7830853563038371\n",
      "Epoch 14/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3692\n",
      "— train_f1: 0.8417210910487899 — val_f1: 0.7809667673716012\n",
      "Epoch 15/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3731\n",
      "— train_f1: 0.8171000440722787 — val_f1: 0.7744755244755245\n",
      "Epoch 16/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— train_f1: 0.8519953506392871 — val_f1: 0.7799227799227799\n",
      "Epoch 17/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3666\n",
      "— train_f1: 0.8466076696165192 — val_f1: 0.7786131996658314\n",
      "Epoch 18/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3587\n",
      "— train_f1: 0.845356462872858 — val_f1: 0.7774030354131535\n",
      "Epoch 19/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3702\n",
      "— train_f1: 0.8472427635748995 — val_f1: 0.7746243739565944\n",
      "Epoch 20/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3596\n",
      "— train_f1: 0.8623816240177312 — val_f1: 0.786624203821656\n",
      "Epoch 21/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3454\n",
      "— train_f1: 0.8589058000822707 — val_f1: 0.7919028340080971\n",
      "Epoch 22/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3586\n",
      "— train_f1: 0.8627209206740649 — val_f1: 0.7864077669902912\n",
      "Epoch 23/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3406\n",
      "— train_f1: 0.8630975143403441 — val_f1: 0.7785234899328858\n",
      "Epoch 24/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3245\n",
      "— train_f1: 0.868720281166012 — val_f1: 0.7779605263157895\n",
      "Epoch 25/25\n",
      "190/190 [==============================] - 2s 10ms/step - loss: 0.3395\n",
      "— train_f1: 0.8749752328115712 — val_f1: 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "metrics = []\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X=X, y=y)):\n",
    "    print('---- Starting fold %d ----'%(k_fold+1))\n",
    "    \n",
    "    x_train, y_train = X[tr_inds], y[tr_inds]\n",
    "    x_val, y_val = X[val_inds], y[val_inds]\n",
    "    model = get_gru_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=[])    \n",
    "    m = Metrics(train=(x_train,y_train), validation=(x_val, y_val))\n",
    "    model.fit(x=x_train, y=y_train, batch_size=32, epochs=25, \n",
    "               callbacks=[m])\n",
    "    metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m in metrics:\n",
    "    scores.append(m.val_f1s[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.753857, 0.761301, 0.772496, 0.766667, 0.783826]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7676293999999999"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "237/237 [==============================] - 4s 10ms/step - loss: 0.6874\n",
      "Epoch 2/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.6597\n",
      "Epoch 3/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4689\n",
      "Epoch 4/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4256\n",
      "Epoch 5/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4311\n",
      "Epoch 6/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4088\n",
      "Epoch 7/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4018\n",
      "Epoch 8/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.4043\n",
      "Epoch 9/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3854\n",
      "Epoch 10/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3943\n",
      "Epoch 11/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3913\n",
      "Epoch 12/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3788\n",
      "Epoch 13/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3674\n",
      "Epoch 14/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3733\n",
      "Epoch 15/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3797\n",
      "Epoch 16/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3701\n",
      "Epoch 17/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3590\n",
      "Epoch 18/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3674\n",
      "Epoch 19/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3569\n",
      "Epoch 20/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3575\n",
      "Epoch 21/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3655\n",
      "Epoch 22/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3641\n",
      "Epoch 23/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3480\n",
      "Epoch 24/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3456\n",
      "Epoch 25/25\n",
      "237/237 [==============================] - 2s 10ms/step - loss: 0.3522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f60a97a81f0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_model = get_gru_model()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "gru_model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=[])    \n",
    "gru_model.fit(x=X, y=y, batch_size=32, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gru_model.predict(X_test)\n",
    "pred = pred.flatten().round()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\":test['id'], \"target\":pred.flatten().round().astype(int)})\n",
    "submission.to_csv('gru.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_lstm_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(8, dropout=0.35, input_shape=(max_words,300)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 9,929\n",
      "Trainable params: 9,913\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_lstm_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Starting fold 1 ----\n",
      "Epoch 1/25\n",
      "189/189 [==============================] - 2s 7ms/step - loss: 0.6545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, random_state=42, shuffle=True)\n",
    "metrics = []\n",
    "for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(X=X, y=y)):\n",
    "    print('---- Starting fold %d ----'%(k_fold+1))\n",
    "    \n",
    "    x_train, y_train = X[tr_inds], y[tr_inds]\n",
    "    x_val, y_val = X[val_inds], y[val_inds]\n",
    "    model = get_lstm_model()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer= optimizer, metrics=[])    \n",
    "    m = Metrics(train=(x_train,y_train), validation=(x_val, y_val))\n",
    "    model.fit(x=x_train, y=y_train, batch_size=32, epochs=25, \n",
    "               callbacks=[m])\n",
    "    metrics.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for m in metrics:\n",
    "    scores.append(m.val_f1s[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
