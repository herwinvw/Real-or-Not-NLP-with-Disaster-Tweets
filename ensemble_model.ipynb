{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model\n",
    "Putting together an ensemble of the average wordvec model and a model using the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvec_train = pd.read_pickle('train_wordvec.pickle')\n",
    "wordvec_test = pd.read_pickle('test_wordvec.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>wordvec</th>\n",
       "      <th>keyword_wordvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                       cleaned_text  \\\n",
       "0       1  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1       1             Forest fire near La Ronge Sask. Canada   \n",
       "2       1  All residents asked to 'shelter in place' are ...   \n",
       "3       1  people receive wildfires evacuation orders in ...   \n",
       "4       1  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                             wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                     keyword_wordvec  \n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...  \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...  \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...  \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...  \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(wordvec_train, on=['id'])\n",
    "test = test.merge(wordvec_test, on=['id'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_char_n</th>\n",
       "      <th>num_words_n</th>\n",
       "      <th>num_hash_n</th>\n",
       "      <th>num_mention_n</th>\n",
       "      <th>num_url_n</th>\n",
       "      <th>has_location</th>\n",
       "      <th>geocoded</th>\n",
       "      <th>longitude_n</th>\n",
       "      <th>latitude_n</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.847134</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.356688</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  num_char_n  num_words_n  num_hash_n  num_mention_n  num_url_n  \\\n",
       "0   1    0.433121     0.419355    0.076923            0.0        0.0   \n",
       "1   4    0.242038     0.225806    0.000000            0.0        0.0   \n",
       "2   5    0.847134     0.709677    0.000000            0.0        0.0   \n",
       "3   6    0.356688     0.225806    0.076923            0.0        0.0   \n",
       "4   7    0.541401     0.516129    0.153846            0.0        0.0   \n",
       "\n",
       "   has_location  geocoded  longitude_n  latitude_n  target  \n",
       "0         False     False          0.0         0.0       1  \n",
       "1         False     False          0.0         0.0       1  \n",
       "2         False     False          0.0         0.0       1  \n",
       "3         False     False          0.0         0.0       1  \n",
       "4         False     False          0.0         0.0       1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tree = pd.read_csv('train_metafeatures_tree.csv')\n",
    "test_tree = pd.read_csv('test_metafeatures_tree.csv')\n",
    "train_normalized = pd.read_csv('train_metafeatures_normalized.csv')\n",
    "test_normalized = pd.read_csv('test_metafeatures_normalized.csv')\n",
    "train_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_char_n</th>\n",
       "      <th>num_words_n</th>\n",
       "      <th>num_hash_n</th>\n",
       "      <th>num_mention_n</th>\n",
       "      <th>num_url_n</th>\n",
       "      <th>has_location</th>\n",
       "      <th>geocoded</th>\n",
       "      <th>longitude_n</th>\n",
       "      <th>latitude_n</th>\n",
       "      <th>target</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>wordvec</th>\n",
       "      <th>keyword_wordvec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "      <td>[-0.26623327, 0.05843069, -0.1404636, -0.05265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.242038</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "      <td>[-0.025449565, 0.031005142, -0.15566371, -0.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.847134</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "      <td>[0.0059339865, 0.016337818, -0.105279535, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.356688</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "      <td>[-0.18147185, 0.20731743, 0.014147284, -0.2182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.541401</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "      <td>[-0.06394094, -0.01423019, 0.0063574947, 0.071...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  num_char_n  num_words_n  num_hash_n  num_mention_n  num_url_n  \\\n",
       "0   1    0.433121     0.419355    0.076923            0.0        0.0   \n",
       "1   4    0.242038     0.225806    0.000000            0.0        0.0   \n",
       "2   5    0.847134     0.709677    0.000000            0.0        0.0   \n",
       "3   6    0.356688     0.225806    0.076923            0.0        0.0   \n",
       "4   7    0.541401     0.516129    0.153846            0.0        0.0   \n",
       "\n",
       "   has_location  geocoded  longitude_n  latitude_n  target keyword location  \\\n",
       "0         False     False          0.0         0.0       1     NaN      NaN   \n",
       "1         False     False          0.0         0.0       1     NaN      NaN   \n",
       "2         False     False          0.0         0.0       1     NaN      NaN   \n",
       "3         False     False          0.0         0.0       1     NaN      NaN   \n",
       "4         False     False          0.0         0.0       1     NaN      NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  Our Deeds are the Reason of this earthquake Ma...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  people receive wildfires evacuation orders in ...   \n",
       "4  Just got sent this photo from Ruby Alaska as s...   \n",
       "\n",
       "                                             wordvec  \\\n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...   \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...   \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...   \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...   \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...   \n",
       "\n",
       "                                     keyword_wordvec  \n",
       "0  [-0.26623327, 0.05843069, -0.1404636, -0.05265...  \n",
       "1  [-0.025449565, 0.031005142, -0.15566371, -0.23...  \n",
       "2  [0.0059339865, 0.016337818, -0.105279535, -0.0...  \n",
       "3  [-0.18147185, 0.20731743, 0.014147284, -0.2182...  \n",
       "4  [-0.06394094, -0.01423019, 0.0063574947, 0.071...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tree = train_tree.merge(train, on=['id','target'])\n",
    "train_normalized = train_normalized.merge(train, on=['id','target'])\n",
    "test_tree = test_tree.merge(test, on=['id'])\n",
    "test_normalized = test_normalized.merge(test, on = ['id'])\n",
    "train_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all data in one SVM model\n",
    "Puts metafeatures and features in one big SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'num_char_n', 'num_words_n', 'num_hash_n', 'num_mention_n',\n",
       "       'num_url_n', 'has_location', 'geocoded', 'longitude_n', 'latitude_n',\n",
       "       'target', 'keyword', 'location', 'text', 'cleaned_text', 'wordvec',\n",
       "       'keyword_wordvec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normalized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def get_X(df, col_wv, cols_ext):\n",
    "    X = []\n",
    "    for index, row in df.iterrows():\n",
    "        x = row[col_wv]\n",
    "        x = numpy.append(row[cols_ext].values, x)\n",
    "        X.append(x)        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ext = ['num_char_n', 'num_words_n', 'num_hash_n', 'num_mention_n',\n",
    "       'num_url_n', 'has_location', 'geocoded', 'longitude_n', 'latitude_n']\n",
    "X = get_X(train_normalized, 'wordvec',cols_ext)\n",
    "y = train_normalized['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "params = {'C': [0.05, 0.1, 0.2, 0.5, 0.75, 1, 1.5, 2, 4]}\n",
    "clf = GridSearchCV(svm, params, scoring=\"f1\", verbose=1, n_jobs=-2, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([158.19189024, 189.40911245, 242.12806582, 265.95231915,\n",
       "        270.01944232]),\n",
       " 'score_time': array([2.1467371 , 2.26172423, 3.16707468, 3.3029592 , 3.25709343]),\n",
       " 'test_score': array([0.76399027, 0.74728941, 0.7749577 , 0.76101695, 0.77564637]),\n",
       " 'train_score': array([0.82279274, 0.79297365, 0.81854249, 0.78786602, 0.79731149])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(clf, X, y, cv=cv, return_train_score=True, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645801390849052"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slight improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(model, X, y, X_test, name):\n",
    "    fit = model.fit(X,y)\n",
    "    pred = model.predict(X_test)\n",
    "    submission = pd.DataFrame({\"id\":test['id'], \"target\":pred})\n",
    "    submission.to_csv(name+'.csv', index=False)\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = get_X(test_normalized, 'wordvec',cols_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  45 out of  45 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "fit = prepare_submission(clf, X, y, X_test, 'avg_wordvec_meta_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a public score improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
